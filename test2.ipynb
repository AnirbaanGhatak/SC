{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to train the Hebbian network\n",
    "def train_hebbian(X, epochs, learning_rate):\n",
    "    # Initialize weights and bias to zero\n",
    "    n_samples, n_features = X.shape\n",
    "    weights = np.zeros(n_features)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_features):\n",
    "                # Apply the Hebbian learning rule\n",
    "                weights[j] += learning_rate * X[i, j] * X[i, j]\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Function to make predictions using the trained Hebbian network\n",
    "def predict_hebbian(X, weights):\n",
    "    return np.dot(X, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20., 20., 40.]), array([40., 60., 60., 80.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input for AND operation\n",
    "X_and = np.array([[0, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 0],\n",
    "                    [1, 1]])\n",
    "\n",
    "# Add a bias \n",
    "X_and_bias = np.hstack([X_and, np.ones((X_and.shape[0], 1))])\n",
    "\n",
    "# Training for AND operation\n",
    "weights_and = train_hebbian(X_and_bias, epochs=100, learning_rate=0.1)\n",
    "\n",
    "# Make predictions\n",
    "predictions_and = predict_hebbian(X_and_bias, weights_and)\n",
    "\n",
    "weights_and, predictions_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20., 20., 40.]), array([40., 60., 60., 80.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input for OR operation\n",
    "X_or = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "\n",
    "# Add a bias \n",
    "X_or_bias = np.hstack([X_or, np.ones((X_or.shape[0], 1))])\n",
    "\n",
    "# Train for OR operation\n",
    "weights_or = train_hebbian(X_or_bias, epochs=100, learning_rate=0.1)\n",
    "\n",
    "# Make predictions\n",
    "predictions_or = predict_hebbian(X_or_bias, weights_or)\n",
    "\n",
    "weights_or, predictions_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10., 20.]), array([20., 30.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input for NOT operation (single input)\n",
    "X_not = np.array([[0],\n",
    "                  [1]])\n",
    "\n",
    "# Add a bias\n",
    "X_not_bias = np.hstack([X_not, np.ones((X_not.shape[0], 1))])\n",
    "\n",
    "# Train for NOT operation\n",
    "weights_not = train_hebbian(X_not_bias, epochs=100, learning_rate=0.1)\n",
    "\n",
    "# Make predictions\n",
    "predictions_not = predict_hebbian(X_not_bias, weights_not)\n",
    "weights_not, predictions_not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20., 20., 40.]), array([40., 60., 60., 80.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input for NAND operation\n",
    "X_nand = np.array([[0, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 0],\n",
    "                    [1, 1]])\n",
    "\n",
    "# Add a bias term to the input\n",
    "X_nand_bias = np.hstack([X_nand, np.ones((X_nand.shape[0], 1))])\n",
    "\n",
    "# Train for NAND operation\n",
    "weights_nand = train_hebbian(X_nand_bias, epochs=100, learning_rate=0.1)\n",
    "\n",
    "# Make predictions\n",
    "predictions_nand = predict_hebbian(X_nand_bias, weights_nand)\n",
    "\n",
    "weights_nand, predictions_nand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20., 20., 40.]), array([40., 60., 60., 80.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nor = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "\n",
    "# Add a bias\n",
    "X_nor_bias = np.hstack([X_nor, np.ones((X_nor.shape[0], 1))])\n",
    "\n",
    "# Train for NOR operation\n",
    "weights_nor = train_hebbian(X_nor_bias, epochs=100, learning_rate=0.1)\n",
    "\n",
    "# Make predictions\n",
    "predictions_nor = predict_hebbian(X_nor_bias, weights_nor)\n",
    "\n",
    "weights_nor, predictions_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20., 20., 40.]), array([60., 40., 80., 60.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input for ANDNOT operation (AND with the NOT of X2)\n",
    "X_andnot = np.array([[0, 1],\n",
    "                     [0, 0],\n",
    "                     [1, 1],\n",
    "                     [1, 0]])\n",
    "\n",
    "# Add a bias\n",
    "X_andnot_bias = np.hstack([X_andnot, np.ones((X_andnot.shape[0], 1))])\n",
    "\n",
    "# Train for ANDNOT operation\n",
    "weights_andnot = train_hebbian(X_andnot_bias, epochs=100, learning_rate=0.1)\n",
    "\n",
    "# Make predictions\n",
    "predictions_andnot = predict_hebbian(X_andnot_bias, weights_andnot)\n",
    "\n",
    "weights_andnot, predictions_andnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20., 20., 40.]), array([40., 60., 60., 80.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input for XOR operation\n",
    "X_xor = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "\n",
    "# Add a bias\n",
    "X_xor_bias = np.hstack([X_xor, np.ones((X_xor.shape[0], 1))])\n",
    "\n",
    "# Train for XOR operation\n",
    "weights_xor = train_hebbian(X_xor_bias, epochs=100, learning_rate=0.1)\n",
    "\n",
    "# Make predictions\n",
    "predictions_xor = predict_hebbian(X_xor_bias, weights_xor)\n",
    "\n",
    "weights_xor, predictions_xor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
